{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cd67ea",
   "metadata": {},
   "source": [
    "# Unsupervised Learning: More Centroid Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bf3a5",
   "metadata": {},
   "source": [
    "For today's small group we'll be diving into centroid clustering algorithms in more depth!\n",
    "\n",
    "First, we need to generate some data to play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a312b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base, y_true = make_blobs(n_samples=300, centers=3, n_features=2, \n",
    "                            cluster_std=0.8, random_state=42)\n",
    "\n",
    "X_base[y_true == 0] = X_base[y_true == 0] * 0.6 + [-8, -6] \n",
    "X_base[y_true == 1] = X_base[y_true == 1] * 0.6 + [0, 8]    \n",
    "X_base[y_true == 2] = X_base[y_true == 2] * 0.6 + [8, -6]   \n",
    "\n",
    "np.random.seed(42)\n",
    "outlier_x = np.linspace(12, 35, 20)  # Long horizontal spread\n",
    "outlier_y = np.random.uniform(-7, -5, 20)  # Some vertical spread\n",
    "outliers = np.column_stack([outlier_x, outlier_y])\n",
    "\n",
    "X = np.vstack([X_base, outliers])\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Plot all data in one color to simulate unsupervised learning\n",
    "plt.scatter(X[:, 0], X[:, 1], c='steelblue', alpha=0.6, s=50)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Dataset with Outliers')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9f957",
   "metadata": {},
   "source": [
    "Notice the outliers? Let's see how these affect our centroid clustering algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb484a05",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861cfb7",
   "metadata": {},
   "source": [
    "## Part 1: Implementing K-Means Clustering\n",
    "\n",
    "### Q: Use sklearn's `KMeans` to cluster the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: Set random_state = 42 so we all get the same results\n",
    "# Create a KMeans object \n",
    "kmeans = KMeans(  YOUR ANSWER HERE  )\n",
    "\n",
    "# Fit the model to the data (delete line below for student version)\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "# Get the cluster labels\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Get the cluster centers\n",
    "#kmeans_centers = kmeans.cluster_centers_\n",
    "\n",
    "print(\"K-Means Clustering Complete!\")\n",
    "print(f\"Cluster centers shape: {kmeans_centers.shape}\")\n",
    "print(f\"Unique labels: {np.unique(kmeans_labels)}\")\n",
    "print(f\"\\nCluster Centers:\\n{kmeans_centers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5b02d",
   "metadata": {},
   "source": [
    "### Visualize K-Means Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "# Scatter plot colored by cluster labels\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=kmeans_labels, \n",
    "               palette='Set1', s=80, alpha=0.6)\n",
    "# Plot cluster centers\n",
    "plt.scatter(kmeans_centers[:, 0], kmeans_centers[:, 1], \n",
    "           c='black', marker='*', s=500, edgecolors='yellow', \n",
    "           linewidths=2, label='K-Means Centers')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('K-Means Clustering Results')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c73c6b",
   "metadata": {},
   "source": [
    "### Q: How did K-Means perform? Did the outliers affect the cluster centers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aab5a9",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8256ee0",
   "metadata": {},
   "source": [
    "### Q: How could we evaluate the performance quantitatively?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4876139",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f222e6d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74b68f",
   "metadata": {},
   "source": [
    "## Part 2: Implementing K-Medians Clustering\n",
    "\n",
    "The median of a cluster is calculated by collecting all points assigned to a cluster and then for each dimension separately sorting all values in that dimension and picking the middle value (median). The point with median value for each dimension is then used as the centeroid.\n",
    "\n",
    "**The goal is to minimize the sum of absolute differences between data points and their assigned centeroid.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec8039b",
   "metadata": {},
   "source": [
    "### Q: Fill in the missing code from the K-Medians function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79e501",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def KMedians(X, n_clusters=3, max_iters=100, random_state=None):\n",
    "    \"\"\"\n",
    "    Implement K-Medians clustering algorithm.\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialize centers randomly by selecting n_clusters random points from X\n",
    "    random_indices = np.random.choice(n_samples, n_clusters, replace=False)\n",
    "    centers = X[random_indices].copy()\n",
    "    \n",
    "    for iteration in range(max_iters):\n",
    "        # Assign each point to the nearest center\n",
    "        labels = np.zeros(n_samples, dtype=int)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # Calculate distance from point i to each center\n",
    "            distances = np.array([ YOUR ANSWER HERE for center in centers])\n",
    "            # Assign label as the index of the closest center\n",
    "            labels[i] = np.argmin(distances)\n",
    "        \n",
    "        # Store old centers to check for convergence\n",
    "        old_centers = centers.copy()\n",
    "        \n",
    "        # Update centers to be the median of points in each cluster\n",
    "        for k in range(n_clusters):\n",
    "            # Get all points assigned to cluster k\n",
    "            cluster_points = YOUR ANSWER HERE\n",
    "            \n",
    "            if len(cluster_points) > 0:\n",
    "                # Calculate median for each dimension\n",
    "                centers[k] = YOUR ANSWER HERE\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.allclose(old_centers, centers):\n",
    "            print(f\"Converged after {iteration + 1} iterations\")\n",
    "            break\n",
    "    \n",
    "    return labels, centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778079b",
   "metadata": {},
   "source": [
    "### Apply K-Medians to the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: Set random_state = 57 so we all get the same results\n",
    "# Apply K-Medians function\n",
    "kmedians_labels, kmedians_centers = KMedians(  YOUR ANSWER HERE  )\n",
    "\n",
    "print(\"K-Medians Clustering Complete!\")\n",
    "print(f\"Cluster centers shape: {kmedians_centers.shape}\")\n",
    "print(f\"Unique labels: {np.unique(kmedians_labels)}\")\n",
    "print(f\"\\nCluster Centers:\\n{kmedians_centers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3803ef",
   "metadata": {},
   "source": [
    "### Visualize K-Medians Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa33c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "# Scatter plot colored by cluster labels\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=kmedians_labels, \n",
    "               palette='Set2', s=80, alpha=0.6)\n",
    "# Plot cluster centers\n",
    "plt.scatter(kmedians_centers[:, 0], kmedians_centers[:, 1], \n",
    "           c='black', marker='D', s=200, edgecolors='orange', \n",
    "           linewidths=2, label='K-Medians Centers')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('K-Medians Clustering Results')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6ba05",
   "metadata": {},
   "source": [
    "## Comparing K-Means vs K-Medians\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f3280",
   "metadata": {},
   "source": [
    "### Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285884f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "# K-Means plot\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=kmeans_labels, \n",
    "               palette='Set1', s=80, alpha=0.6, ax=axes[0])\n",
    "axes[0].scatter(kmeans_centers[:, 0], kmeans_centers[:, 1], \n",
    "               c='black', marker='*', s=500, edgecolors='yellow', \n",
    "               linewidths=2, label='Centers')\n",
    "axes[0].set_title('KMeans')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend(fontsize=12)\n",
    "\n",
    "# K-Medians plot\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=kmedians_labels, \n",
    "               palette='Set2', s=80, alpha=0.6, ax=axes[1])\n",
    "axes[1].scatter(kmedians_centers[:, 0], kmedians_centers[:, 1], \n",
    "               c='black', marker='D', s=200, edgecolors='orange', \n",
    "               linewidths=2, label='Centers')\n",
    "axes[1].set_title('KMedians')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02210fa6",
   "metadata": {},
   "source": [
    "### Q: Which algorithm performed better on the dataset with outliers? \n",
    "\n",
    "Please explain your reasoning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df365ba",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b0891",
   "metadata": {},
   "source": [
    "Imagine we used this process for customer segmentation:\n",
    "\n",
    "- **K-Means**: Might create a \"customer profile\" that doesn't represent any real customer (pulled by outliers)\n",
    " - **K-Medians**: Creates a profile that represents typical customers in the cluster\n",
    "\n",
    "### Key Idea üí°\n",
    "The outliers were assigned to clusters in both cases, but:\n",
    "\n",
    "- K-Means let them distort the cluster centers\n",
    "- K-Medians kept the centers true to the main group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0f7f0",
   "metadata": {},
   "source": [
    "### Testing on Normally Distributed Data\n",
    "\n",
    "Normally distributed data has the same mean, median, and mode\n",
    "\n",
    "<p align=\"left\">\n",
    "    <img src = \"https://ift.world/wp-content/uploads/2018/06/L1-V1-25_2.jpg\" width = \"400\">\n",
    "</p>\n",
    "\n",
    "Let's create some normally distributed clusters to experiment with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean dataset with normally distributed clusters\n",
    "X_normal, y_normal_true = make_blobs(n_samples=300, centers=3, n_features=2, \n",
    "                                     cluster_std=1.5, random_state=42)\n",
    "\n",
    "print(f\"Normal dataset shape: {X_normal.shape}\")\n",
    "\n",
    "# Visualize the dataset\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.scatterplot(x=X_normal[:, 0], y=X_normal[:, 1], \n",
    "               hue=y_normal_true, palette='viridis', s=80, alpha=0.6)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Normally Distributed Clusters (No Outliers)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945c596",
   "metadata": {},
   "source": [
    "### Q: Apply both algorithms to the normally distributed clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e552f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: Set random_state = 42 for both algorithms\n",
    "# Apply K-Means\n",
    "kmeans_normal = KMeans(  YOUR ANSWER HERE  )\n",
    "kmeans_normal.fit(   YOUR ANSWER HERE   )\n",
    "kmeans_normal_labels = kmeans_normal.labels_\n",
    "kmeans_normal_centers = kmeans_normal.cluster_centers_\n",
    "\n",
    "# Apply K-Medians\n",
    "kmedians_normal_labels, kmedians_normal_centers = KMedians(  YOUR ANSWER HERE  )\n",
    "\n",
    "print(\"Clustering on normal data complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c40740",
   "metadata": {},
   "source": [
    "### Visualize Both Results on Normal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5709e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "# K-Means plot\n",
    "sns.scatterplot(x=X_normal[:, 0], y=X_normal[:, 1], hue=kmeans_normal_labels, \n",
    "               palette='Set1', s=80, alpha=0.6, ax=axes[0])\n",
    "axes[0].scatter(kmeans_normal_centers[:, 0], kmeans_normal_centers[:, 1], \n",
    "               c='black', marker='*', s=500, edgecolors='yellow', \n",
    "               linewidths=2, label='Centers')\n",
    "axes[0].set_title('KMeans')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend(fontsize=12)\n",
    "\n",
    "# K-Medians plot\n",
    "sns.scatterplot(x=X_normal[:, 0], y=X_normal[:, 1], hue=kmedians_normal_labels, \n",
    "               palette='Set2', s=80, alpha=0.6, ax=axes[1])\n",
    "axes[1].scatter(kmedians_normal_centers[:, 0], kmedians_normal_centers[:, 1], \n",
    "               c='black', marker='D', s=200, edgecolors='orange', \n",
    "               linewidths=2, label='Centers')\n",
    "axes[1].set_title('KMedians')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b745a63",
   "metadata": {},
   "source": [
    "### Q: How do the performances compare on normally distributed data? Are they similar or different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366fb4b",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08793740",
   "metadata": {},
   "source": [
    "----\n",
    "## Closing Questions üßê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11137960",
   "metadata": {},
   "source": [
    "### 1. When would you choose K-Means over K-Medians? \n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd1d82",
   "metadata": {},
   "source": [
    "### 2. When would you choose K-Medians over K-Means?\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f1511",
   "metadata": {},
   "source": [
    "### 3. What are the main limitations of both algorithms?\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c1bd1",
   "metadata": {},
   "source": [
    "### 4. Can you think of a real-world scenario where outliers might significantly impact clustering?\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
