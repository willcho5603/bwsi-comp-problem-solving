{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e2b558",
   "metadata": {},
   "source": [
    "# Unsupervised Learning: More Density Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN, OPTICS\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5adfb",
   "metadata": {},
   "source": [
    "Learning objectives:\n",
    "- Practice implementing density clustering\n",
    "- Practice visualizing and evaluating performance\n",
    "- Understand the subtle differences between different density clustering algorithms\n",
    "\n",
    "Notes:\n",
    "- Use `sklearn.datasets` as needed\n",
    "- Put all import statements at the top of this notebook\n",
    "- Use `sns.scatterplot` to plot the clusters (e.g. `hue=color_var`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167438a",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We'll work with two synthetic datasets to explore how density clustering handles different density scenarios:\n",
    "\n",
    "1. **Dataset 1**: Noisy concentric circles with **even density** (uniformly distributed points)\n",
    "2. **Dataset 2**: Clusters with **very uneven density** (dense, medium, and sparse clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278vqd2gij",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: Noisy concentric circles with even density\n",
    "np.random.seed(42)\n",
    "X_circles, y_circles = make_circles(n_samples=1000, factor=0.5, noise=0.05)\n",
    "\n",
    "# Visualize the dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_circles[:, 0], y=X_circles[:, 1], alpha=0.6)\n",
    "plt.title('Dataset 1: Noisy Concentric Circles (Even Density)')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Dataset shape: {X_circles.shape}\")\n",
    "print(f\"Notice: Both circles have the same point density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6vh42dnsv57",
   "metadata": {},
   "outputs": [],
   "source": "# Dataset 2: Clusters with very uneven density\n# Create multiple blobs with very different standard deviations to simulate extreme varying densities\nnp.random.seed(42)\n\n# Very dense cluster (very small std, many points)\nX_dense = np.random.randn(400, 2) * 0.3 + np.array([0, 0])\n\n# Medium density cluster\nX_medium = np.random.randn(250, 2) * 0.6 + np.array([3, 3])\n\n# Very sparse cluster (large std, fewer points)\nX_sparse = np.random.randn(150, 2) * 0.9 + np.array([-3, 2])\n\n# Combine all clusters\nX_uneven = np.vstack([X_dense, X_medium, X_sparse])\n\n# Visualize the dataset\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=X_uneven[:, 0], y=X_uneven[:, 1], alpha=0.6)\nplt.title('Dataset 2: Clusters with Very Uneven Density')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.axis('equal')\nplt.show()\n\nprint(f\"Dense cluster: 400 points, std=0.3\")\nprint(f\"Medium cluster: 250 points, std=0.6\")\nprint(f\"Sparse cluster: 150 points, std=0.9\")\nprint(f\"Notice: Very different densities within the same dataset!\")"
  },
  {
   "cell_type": "markdown",
   "id": "8ae6f741",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Part 1: DBSCAN Clustering\n",
    "\n",
    "**Quick Parameter Guide:**\n",
    "- `eps`: Maximum distance between two points to be considered neighbors\n",
    "  - Too small → Everything becomes noise\n",
    "  - Too large → Everything merges into one cluster\n",
    "  - **Hint**: For Dataset 1 (circles), try values around 0.15-0.20\n",
    "  - **Hint**: For Dataset 2 (uneven), you'll need to experiment more!\n",
    "- `min_samples`: Minimum number of points to form a dense region\n",
    "  - **Hint**: Start with 5\n",
    "\n",
    "### Q: Use `sklearn`'s `DBSCAN` to cluster both datasets\n",
    "\n",
    "Try different `eps` values to see what works best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN on Dataset 1: Noisy Concentric Circles (Even Density)\n",
    "# YOUR CODE HERE\n",
    "# dbscan_circles = DBSCAN(eps=    , min_samples=    )\n",
    "# labels_dbscan_circles = dbscan_circles.fit_predict(     )\n",
    "\n",
    "# Visualize clustering results\n",
    "# YOUR CODE HERE\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(x=     , y=     , hue=     , palette='Set1', alpha=0.7, legend='full')\n",
    "# plt.title('DBSCAN on Concentric Circles (Even Density)')\n",
    "# plt.xlabel('Feature 1')\n",
    "# plt.ylabel('Feature 2')\n",
    "# plt.axis('equal')\n",
    "# plt.show()\n",
    "\n",
    "# Print clustering statistics\n",
    "# YOUR CODE HERE\n",
    "# n_clusters_circles = len(set(labels_dbscan_circles)) - (1 if -1 in labels_dbscan_circles else 0)\n",
    "# n_noise_circles = list(labels_dbscan_circles).count(-1)\n",
    "# print(f\"Number of clusters: {n_clusters_circles}\")\n",
    "# print(f\"Number of noise points: {n_noise_circles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67653892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN on Dataset 2: Uneven Density Clusters\n",
    "# YOUR CODE HERE\n",
    "# dbscan_uneven = DBSCAN(eps=    , min_samples=    )\n",
    "# labels_dbscan_uneven = dbscan_uneven.fit_predict(     )\n",
    "\n",
    "# Visualize clustering results\n",
    "# YOUR CODE HERE\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(x=     , y=     , hue=     , palette='Set2', alpha=0.7, legend='full')\n",
    "# plt.title('DBSCAN on Uneven Density')\n",
    "# plt.xlabel('Feature 1')\n",
    "# plt.ylabel('Feature 2')\n",
    "# plt.axis('equal')\n",
    "# plt.show()\n",
    "\n",
    "# Print clustering statistics\n",
    "# YOUR CODE HERE\n",
    "# n_clusters_uneven = len(set(labels_dbscan_uneven)) - (1 if -1 in labels_dbscan_uneven else 0)\n",
    "# n_noise_uneven = list(labels_dbscan_uneven).count(-1)\n",
    "# print(f\"Number of clusters: {n_clusters_uneven}\")\n",
    "# print(f\"Number of noise points: {n_noise_uneven}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc477f3",
   "metadata": {},
   "source": [
    "### Q: Compute quantitative evaluation metrics for DBSCAN\n",
    "\n",
    "Use the clustering metrics we imported (`silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`) to evaluate DBSCAN's performance on both datasets.\n",
    "\n",
    "**Important:** Exclude noise points (label = -1) when computing these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957kw3sdhml",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate DBSCAN on Dataset 1 (Even Density Circles)\n",
    "# YOUR CODE HERE\n",
    "# Filter out noise points first\n",
    "# mask_circles = labels_dbscan_circles != -1\n",
    "# \n",
    "# if mask_circles.sum() > 0 and len(set(labels_dbscan_circles[mask_circles])) > 1:\n",
    "#     silhouette_dbscan_circles = silhouette_score(     ,     )\n",
    "#     davies_bouldin_dbscan_circles = davies_bouldin_score(     ,     )\n",
    "#     calinski_dbscan_circles = calinski_harabasz_score(     ,     )\n",
    "#     \n",
    "#     print(\"DBSCAN Performance on Dataset 1 (Even Density Circles):\")\n",
    "#     print(f\"  Silhouette Score: {silhouette_dbscan_circles:.4f} (higher is better, range: -1 to 1)\")\n",
    "#     print(f\"  Davies-Bouldin Index: {davies_bouldin_dbscan_circles:.4f} (lower is better)\")\n",
    "#     print(f\"  Calinski-Harabasz Index: {calinski_dbscan_circles:.4f} (higher is better)\")\n",
    "\n",
    "# Evaluate DBSCAN on Dataset 2 (Uneven Density)\n",
    "# YOUR CODE HERE\n",
    "# mask_uneven = labels_dbscan_uneven != -1\n",
    "# \n",
    "# if mask_uneven.sum() > 0 and len(set(labels_dbscan_uneven[mask_uneven])) > 1:\n",
    "#     silhouette_dbscan_uneven = silhouette_score(     ,     )\n",
    "#     davies_bouldin_dbscan_uneven = davies_bouldin_score(     ,     )\n",
    "#     calinski_dbscan_uneven = calinski_harabasz_score(     ,     )\n",
    "#     \n",
    "#     print(\"\\nDBSCAN Performance on Dataset 2 (Uneven Density):\")\n",
    "#     print(f\"  Silhouette Score: {silhouette_dbscan_uneven:.4f}\")\n",
    "#     print(f\"  Davies-Bouldin Index: {davies_bouldin_dbscan_uneven:.4f}\")\n",
    "#     print(f\"  Calinski-Harabasz Index: {calinski_dbscan_uneven:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "odfs26e46j",
   "metadata": {},
   "source": [
    "### Q: Based on the metrics above, how did DBSCAN perform on each dataset? \n",
    "\n",
    "Compare Dataset 1 (even density) vs Dataset 2 (uneven density). Which was easier for DBSCAN to cluster? Did you need to use different `eps` values for the two datasets?\n",
    "\n",
    "### A:\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3d3dd",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Part 2: OPTICS Clustering\n",
    "\n",
    "**OPTICS** (Ordering Points To Identify the Clustering Structure) is similar to DBSCAN but can handle clusters with varying densities better. Unlike DBSCAN which requires a fixed `eps` parameter, OPTICS creates a reachability plot that can identify clusters at different density levels.\n",
    "\n",
    "**Key differences from DBSCAN:**\n",
    "- Can find clusters of varying densities\n",
    "- Uses `max_eps` instead of fixed `eps`\n",
    "- More computationally expensive\n",
    "\n",
    "**Resources:**\n",
    "- [Wikipedia article](https://en.wikipedia.org/wiki/OPTICS_algorithm)\n",
    "- [sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0fad3",
   "metadata": {},
   "source": "**Quick Parameter Guide:**\n- `min_samples`: Same meaning as in DBSCAN (try 5)\n- `xi`: Steepness threshold for cluster extraction (try 0.05)\n  - Controls how OPTICS extracts clusters from the reachability plot\n  - Lower values → more clusters, higher values → fewer clusters\n- `min_cluster_size`: Minimum fraction of samples in a cluster (try 0.05)\n  - Helps avoid tiny clusters\n\n**Hint**: Using `xi` and `min_cluster_size` gives better results than just `max_eps`!\n\n### Q: Use `sklearn`'s `OPTICS` to cluster both datasets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7122c388",
   "metadata": {},
   "outputs": [],
   "source": "# OPTICS on Dataset 1: Noisy Concentric Circles (Even Density)\n# YOUR CODE HERE\n# optics_circles = OPTICS(min_samples=    , xi=    , min_cluster_size=    )\n# labels_optics_circles = optics_circles.fit_predict(     )\n\n# Visualize clustering results\n# YOUR CODE HERE\n# plt.figure(figsize=(10, 6))\n# sns.scatterplot(x=     , y=     , hue=     , palette='Set1', alpha=0.7, legend='full')\n# plt.title('OPTICS on Concentric Circles (Even Density)')\n# plt.xlabel('Feature 1')\n# plt.ylabel('Feature 2')\n# plt.axis('equal')\n# plt.show()\n\n# Print clustering statistics\n# YOUR CODE HERE\n# n_clusters_optics_circles = len(set(labels_optics_circles)) - (1 if -1 in labels_optics_circles else 0)\n# n_noise_optics_circles = list(labels_optics_circles).count(-1)\n# print(f\"Number of clusters: {n_clusters_optics_circles}\")\n# print(f\"Number of noise points: {n_noise_optics_circles}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442cf144",
   "metadata": {},
   "outputs": [],
   "source": "# OPTICS on Dataset 2: Uneven Density Clusters\n# YOUR CODE HERE\n# optics_uneven = OPTICS(min_samples=    , xi=    , min_cluster_size=    )\n# labels_optics_uneven = optics_uneven.fit_predict(     )\n\n# Visualize clustering results\n# YOUR CODE HERE\n# plt.figure(figsize=(10, 6))\n# sns.scatterplot(x=     , y=     , hue=     , palette='Set2', alpha=0.7, legend='full')\n# plt.title('OPTICS on Uneven Density')\n# plt.xlabel('Feature 1')\n# plt.ylabel('Feature 2')\n# plt.axis('equal')\n# plt.show()\n\n# Print clustering statistics\n# YOUR CODE HERE\n# n_clusters_optics_uneven = len(set(labels_optics_uneven)) - (1 if -1 in labels_optics_uneven else 0)\n# n_noise_optics_uneven = list(labels_optics_uneven).count(-1)\n# print(f\"Number of clusters: {n_clusters_optics_uneven}\")\n# print(f\"Number of noise points: {n_noise_optics_uneven}\")"
  },
  {
   "cell_type": "markdown",
   "id": "y9tlrlvwimp",
   "metadata": {},
   "source": [
    "### Q: Compute quantitative evaluation metrics for OPTICS\n",
    "\n",
    "Use the same metrics to evaluate OPTICS's performance on both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jogxw2h6iwd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate OPTICS on Dataset 1 (Even Density Circles)\n",
    "# YOUR CODE HERE\n",
    "# mask_optics_circles = labels_optics_circles != -1\n",
    "# \n",
    "# if mask_optics_circles.sum() > 0 and len(set(labels_optics_circles[mask_optics_circles])) > 1:\n",
    "#     silhouette_optics_circles = silhouette_score(     ,     )\n",
    "#     davies_bouldin_optics_circles = davies_bouldin_score(     ,     )\n",
    "#     calinski_optics_circles = calinski_harabasz_score(     ,     )\n",
    "#     \n",
    "#     print(\"OPTICS Performance on Dataset 1 (Even Density Circles):\")\n",
    "#     print(f\"  Silhouette Score: {silhouette_optics_circles:.4f}\")\n",
    "#     print(f\"  Davies-Bouldin Index: {davies_bouldin_optics_circles:.4f}\")\n",
    "#     print(f\"  Calinski-Harabasz Index: {calinski_optics_circles:.4f}\")\n",
    "\n",
    "# Evaluate OPTICS on Dataset 2 (Uneven Density)\n",
    "# YOUR CODE HERE\n",
    "# mask_optics_uneven = labels_optics_uneven != -1\n",
    "# \n",
    "# if mask_optics_uneven.sum() > 0 and len(set(labels_optics_uneven[mask_optics_uneven])) > 1:\n",
    "#     silhouette_optics_uneven = silhouette_score(     ,     )\n",
    "#     davies_bouldin_optics_uneven = davies_bouldin_score(     ,     )\n",
    "#     calinski_optics_uneven = calinski_harabasz_score(     ,     )\n",
    "#     \n",
    "#     print(\"\\nOPTICS Performance on Dataset 2 (Uneven Density):\")\n",
    "#     print(f\"  Silhouette Score: {silhouette_optics_uneven:.4f}\")\n",
    "#     print(f\"  Davies-Bouldin Index: {davies_bouldin_optics_uneven:.4f}\")\n",
    "#     print(f\"  Calinski-Harabasz Index: {calinski_optics_uneven:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc870f4",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Part 3: Comparing DBSCAN vs. OPTICS\n",
    "\n",
    "Now let's compare the two algorithms side-by-side to understand their strengths and weaknesses.\n",
    "\n",
    "### Q: Create a comparison table of performance metrics\n",
    "\n",
    "Use a pandas DataFrame to compare the performance metrics for all four combinations:\n",
    "- DBSCAN on Circles vs OPTICS on Circles\n",
    "- DBSCAN on Uneven Density vs OPTICS on Uneven Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6hpfszmujv5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "# YOUR CODE HERE\n",
    "# comparison_data = [\n",
    "#     {\n",
    "#         'Dataset': 'Even Density (Circles)',\n",
    "#         'Algorithm': 'DBSCAN',\n",
    "#         'Clusters': n_clusters_circles,\n",
    "#         'Noise Points': n_noise_circles,\n",
    "#         'Silhouette': silhouette_dbscan_circles,\n",
    "#         'Davies-Bouldin': davies_bouldin_dbscan_circles,\n",
    "#         'Calinski-Harabasz': calinski_dbscan_circles\n",
    "#     },\n",
    "#     {\n",
    "#         'Dataset': 'Even Density (Circles)',\n",
    "#         'Algorithm': 'OPTICS',\n",
    "#         'Clusters':     ,\n",
    "#         'Noise Points':     ,\n",
    "#         'Silhouette':     ,\n",
    "#         'Davies-Bouldin':     ,\n",
    "#         'Calinski-Harabasz':     \n",
    "#     },\n",
    "#     # Add two more dictionaries for the Uneven Density dataset\n",
    "#     # YOUR CODE HERE\n",
    "# ]\n",
    "# \n",
    "# df_comparison = pd.DataFrame(comparison_data)\n",
    "# print(df_comparison.to_string(index=False))\n",
    "# print(\"\\nReminder: Silhouette & Calinski-Harabasz → higher is better | Davies-Bouldin → lower is better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unyz8kt5xx",
   "metadata": {},
   "source": [
    "### Q: Create side-by-side visualizations comparing the clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01epdy8chchp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison: Dataset 1 (Even Density Circles)\n",
    "# YOUR CODE HERE (Uncomment and fill in the blanks)\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# # DBSCAN\n",
    "# sns.scatterplot(x=     , y=     , hue=     , palette='Set1', alpha=0.7, legend='full', ax=axes[0])\n",
    "# axes[0].set_title(f'DBSCAN on Even Density Circles')\n",
    "# axes[0].set_xlabel('Feature 1')\n",
    "# axes[0].set_ylabel('Feature 2')\n",
    "# axes[0].axis('equal')\n",
    "\n",
    "# # OPTICS\n",
    "# sns.scatterplot(x=     , y=     , hue=     , palette='Set1', alpha=0.7, legend='full', ax=axes[1])\n",
    "# axes[1].set_title(f'OPTICS on Even Density Circles')\n",
    "# axes[1].set_xlabel('Feature 1')\n",
    "# axes[1].set_ylabel('Feature 2')\n",
    "# axes[1].axis('equal')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933o6ld2nqc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison: Dataset 2 (Uneven Density)\n",
    "# YOUR CODE HERE (Uncomment and fill in the blanks)\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# # DBSCAN\n",
    "# sns.scatterplot(x=     , y=     , hue=     , palette='Set2', alpha=0.7, legend='full', ax=axes[0])\n",
    "# axes[0].set_title(f'DBSCAN on Uneven Density')\n",
    "# axes[0].set_xlabel('Feature 1')\n",
    "# axes[0].set_ylabel('Feature 2')\n",
    "# axes[0].axis('equal')\n",
    "\n",
    "# # OPTICS\n",
    "# sns.scatterplot(x=     , y=     , hue=     , palette='Set2', alpha=0.7, legend='full', ax=axes[1])\n",
    "# axes[1].set_title(f'OPTICS on Uneven Density')\n",
    "# axes[1].set_xlabel('Feature 1')\n",
    "# axes[1].set_ylabel('Feature 2')\n",
    "# axes[1].axis('equal')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o0b3tm4uows",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "1. **DBSCAN on Even vs Uneven Density**: Compare DBSCAN's performance on Dataset 1 (even density circles) vs Dataset 2 (very uneven density). On which dataset did DBSCAN perform better? Why?\n",
    "\n",
    "2. **The Key Challenge**: On Dataset 2, did you struggle to find a single `eps` value that worked well for all three clusters? What happened when you used:\n",
    "   - A small `eps` (good for the dense cluster)?\n",
    "   - A large `eps` (good for the sparse cluster)?\n",
    "\n",
    "3. **OPTICS to the Rescue**: How did OPTICS handle Dataset 2 compared to DBSCAN? Did it successfully identify all three clusters without you having to manually tune `eps` for each density level?\n",
    "\n",
    "4. **When is DBSCAN Sufficient?**: Based on your results, when would you use DBSCAN instead of OPTICS? (Hint: Think about Dataset 1's results and computational cost)\n",
    "\n",
    "5. **Trade-offs**: OPTICS is more computationally expensive than DBSCAN. Given what you observed:\n",
    "   - When is the extra cost worth it?\n",
    "   - When can you get away with using simpler, faster DBSCAN?\n",
    "\n",
    "6. **Real-World Application**: Imagine clustering customer locations in a city where:\n",
    "   - Downtown has very dense clusters (many customers in small area)\n",
    "   - Suburbs have sparse clusters (few customers spread out)\n",
    "   \n",
    "   Which algorithm would you choose and why? What problems might you encounter with each?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zotvfyfhjt",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWERS HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}