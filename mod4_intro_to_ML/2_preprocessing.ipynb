{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro-0001",
      "metadata": {},
      "source": [
        "# Intro to ML: Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "why-preprocess-0002",
      "metadata": {},
      "source": [
        "## When and Why Preprocess?\n",
        "Machine learning models work best when data is clean, consistent, and comparable. **Preprocessing** means preparing data so that itâ€™s fair and understandable to your model.\n",
        "\n",
        "Think about it like baking cookiesâ€”if your ingredients arenâ€™t measured in the same units (cups vs. grams), the result might beâ€¦ weird.\n",
        "\n",
        "**Reasons to preprocess:**\n",
        "- Fix messy or missing data.\n",
        "- Put features on similar scales so no one feature dominates.\n",
        "- Convert categories (like colors or fruit names) into numbers so computers can read them.\n",
        "\n",
        "### ğŸª Example:\n",
        "Youâ€™re building a model to predict which cookie recipe people like best. Your dataset includes:\n",
        "- Sugar (grams)\n",
        "- Baking time (minutes)\n",
        "- Cookie type (chocolate chip, oatmeal, sugar)\n",
        "- Rating (1â€“5 stars)\n",
        "\n",
        "Before training your model, youâ€™d want to:\n",
        "1. Make sure sugar and baking time are in consistent units.\n",
        "2. Convert cookie type into numbers.\n",
        "3. Possibly scale features so that grams and minutes donâ€™t overpower each other.\n",
        "\n",
        "### ğŸ’¡ Question 1:\n",
        "Why might a model get confused if 'baking time' is measured in minutes but 'sugar' is in teaspoons?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scaling-0003",
      "metadata": {},
      "source": [
        "## Scaling\n",
        "Scaling ensures that features measured in different units donâ€™t unfairly influence the model.\n",
        "\n",
        "**Example:**\n",
        "Imagine a model comparing two features:\n",
        "- Height (in centimeters, ~100â€“200)\n",
        "- Age (in years, ~1â€“100)\n",
        "\n",
        "Without scaling, the model might think height matters more, simply because the numbers are larger.\n",
        "\n",
        "**Two common types of scaling:**\n",
        "- **Standard scaling**: centers data around 0, so most values fall between -1 and 1.\n",
        "- **Min-max scaling**: squishes everything between 0 and 1.\n",
        "\n",
        "### ğŸ€ Fun Example:\n",
        "If youâ€™re analyzing NBA player stats (height in cm, points per game, salary in dollars), youâ€™d want to scale them before predicting something like â€œAll-Star potential.â€ Otherwise, the model might think money = talent.\n",
        "\n",
        "### ğŸ’¡ Question 2:\n",
        "Which would you use in this caseâ€”StandardScaler or MinMaxScalerâ€”and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "encoding-0004",
      "metadata": {},
      "source": [
        "## Encoding\n",
        "Models canâ€™t understand wordsâ€”they need numbers. **Encoding** is how we convert categories into numeric form.\n",
        "\n",
        "**Two common encoding types:**\n",
        "- **One-Hot Encoding**: Turns each category into a new column (useful for non-ordered categories).\n",
        "  - Example: 'cookie type' â†’ chocolate chip = [1,0,0], oatmeal = [0,1,0], sugar = [0,0,1].\n",
        "- **Ordinal Encoding**: Assigns numeric ranks to ordered categories.\n",
        "  - Example: 'spiciness' â†’ low = 1, medium = 2, high = 3.\n",
        "\n",
        "**Analogy:** If One-Hot Encoding is like making separate scoreboards for each team, Ordinal Encoding is like ranking teams 1st, 2nd, and 3rd.\n",
        "\n",
        "### ğŸ¦ Example:\n",
        "Youâ€™re training an ice cream shop model to predict flavor popularity. The dataset includes flavor (vanilla, chocolate, strawberry) and average weekly sales.\n",
        "Youâ€™d need to encode these flavors as numbers before training.\n",
        "\n",
        "### ğŸ’¡ Question 3:\n",
        "Why might 'vanilla=1, chocolate=2, strawberry=3' be misleading for a model?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pca-0005",
      "metadata": {},
      "source": [
        "## Principal Component Analysis (PCA)\n",
        "PCA is a way to **simplify complex data** by reducing the number of features, while keeping most of the important information.\n",
        "\n",
        "**Imagine:** You have a 10-feature dataset of cookies (sugar, flour, butter, etc.). PCA can help compress those into 2â€“3 features that still describe most of the variation in recipes.\n",
        "\n",
        "This makes it easier to visualize patterns and can speed up learning.\n",
        "\n",
        "### ğŸ¨ Fun Example:\n",
        "Suppose you have 1,000 photos of sneakers with features like color intensity, texture, and brightness. PCA can reduce all that down to just two â€œsummaryâ€ features that let you plot the shoes in 2Dâ€”red vs. blue shoes might form distinct clusters.\n",
        "\n",
        "**However:** Reducing too much can mean losing key details (like brand logos or unique designs).\n",
        "\n",
        "### ğŸ’¡ Discussion Prompt:\n",
        "If you reduced 1,000 sneaker features to just 2, what might the model lose in its ability to classify shoes?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wrapup-0006",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "- **Preprocessing** prepares your data to be fair and consistent.\n",
        "- **Scaling** ensures features measured in different units donâ€™t overpower one another.\n",
        "- **Encoding** lets computers understand categorical data.\n",
        "- **PCA** reduces complexity while keeping the main patterns.\n",
        "\n",
        "**In short:** Before teaching a computer to learn, make sure the data speaks the same language!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
