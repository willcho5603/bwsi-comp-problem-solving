{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ed6989",
   "metadata": {},
   "source": [
    "# Deep Learning: More Convolutional Neural Networks\n",
    "\n",
    "Welcome back! Today’s small–group lecture explores **Convolutional Neural Networks (CNNs)**, building directly on what we've learned so far in deep learning.\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "- Understand the intuition behind CNNs and why they work so well for image data.\n",
    "- Build a multi-layer PyTorch CNN from scratch.\n",
    "- Explain the role of activation functions, batch normalization, and max pooling.\n",
    "- Train, validate, and analyze a CNN’s performance.\n",
    "- Understand core training concepts such as optimizers, loss functions, epochs, and learning rate.\n",
    "\n",
    "This lecture is designed to feel like a guided walkthrough — with explanations of not just **what** we do, but **why** we do it.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147a4157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.3.1.post100\n",
      "Torchvision version: 0.18.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"Pytorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f632b4",
   "metadata": {},
   "source": [
    "### Note: Python must be 3.11.x\n",
    "\n",
    "If your kernel shows a value > 3.11.x you will need to downgrade. Please email the staff for help.\n",
    "\n",
    "**Why does this matter?** Some PyTorch wheels break under Python 3.12 due to ABI changes. Always confirm version compatibility when working with deep learning frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc40539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# DEVICE CONFIGURATION\n",
    "if torch.backends.mps.is_available():          # Apple Silicon\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():                # CUDA GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")               # Fallback\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9dc771",
   "metadata": {},
   "source": [
    "For today's small group, we will walk through the process of setting up a convolutional neural network (\"CNN\" for short) using the `pytorch` package!\n",
    "\n",
    "CNNs shine when working with **structured grid data**, especially images — tasks like classification, segmentation, object detection, and more.\n",
    "\n",
    "Why? Because CNNs:\n",
    "- Capture local patterns (edges, textures) via **convolutions**.\n",
    "- Build hierarchical features (shapes → objects) through **stacked layers**.\n",
    "- Use **shared weights**, making them efficient and translation-invariant.\n",
    "\n",
    "Let’s load a dataset so we can see these ideas in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e677b0b9",
   "metadata": {},
   "source": [
    "Recall from lecture that CNNs are generally used to process gridded data or images.\n",
    "\n",
    "Let's begin by loading one of the toy datasets included in `pytorch`: **CIFAR-10**.\n",
    "\n",
    "The dataset contains 60,000 small 32×32 color images belonging to 10 different classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dba6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init preprocessing for CIFAR-10 dataset (images are 32x32x3)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # normalize to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6085fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a204a",
   "metadata": {},
   "source": [
    "Great! We have image data now. But what does it look like?\n",
    "\n",
    "Visualizing your data is an essential first step — especially in computer vision.\n",
    "\n",
    "Let's plot the different classes below using `matplotlib`. When teaching, this is a great moment to ask:\n",
    "- *What patterns do you notice?*\n",
    "- *Which classes might be harder for the network? Why?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a300eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each class here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d308dd",
   "metadata": {},
   "source": [
    "## Building a CNN\n",
    "\n",
    "Staff:\n",
    "- Reference lecture: CNNs involve stacking multiple **layers**\n",
    "- The first part of a CNN involves stacking multiple layers of convolutional, activation, and maxpool layers \n",
    "- The example code below shows 3 of these stacks of layers!\n",
    "<p align=\"left\">\n",
    "    <img src = \"https://media.geeksforgeeks.org/wp-content/uploads/20250529121802516451/Convolutional-Neural-Network-in-Machine-Learning.webp\" width = \"500\">\n",
    "</p>\n",
    "\n",
    "### Activation Functions\n",
    "\n",
    "Staff:\n",
    "- Please briefly review some of the common activation functions (there will be a table on this at the beginning of lecture)\n",
    "- Discuss 3 of the most common activation functions\n",
    "- Be sure to define what their names are in tensorflow\n",
    "\n",
    "### Expanded Notes for Staff\n",
    "- **ReLU**: fast, avoids vanishing gradients. TensorFlow: `tf.nn.relu` or `tf.keras.layers.ReLU()`.\n",
    "- **LeakyReLU**: avoids dead neurons by allowing small negative gradient. TF: `tf.nn.leaky_relu`.\n",
    "- **Tanh**: zero-centered but saturates. TF: `tf.nn.tanh`.\n",
    "\n",
    "Explain *why* we use nonlinear activations: without them, a stack of layers collapses to a single linear transformation — making the network unable to model complex patterns.\n",
    "\n",
    "Please add comments to this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11039ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),        # 1st conv layer\n",
    "            nn.BatchNorm2d(32),                                # normalize activations\n",
    "            nn.ReLU(),                                         # nonlinear activation\n",
    "            nn.MaxPool2d(2)                                    # reduces image size\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Linear(128*4*4, 10)  # CIFAR-10 has 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad2320e",
   "metadata": {},
   "source": [
    "### Q: What do you think will happen to your CNN as you change the activation function?\n",
    "Feel free to try this by changing `activation_func`!\n",
    "\n",
    "### A:\n",
    "Different activation functions drastically change how gradients behave. For example:\n",
    "- **ReLU**: fast, stable, common default choice.\n",
    "- **Sigmoid**: gradients vanish → poor performance.\n",
    "- **Tanh**: better than sigmoid but still saturates.\n",
    "- **LeakyReLU**: may improve performance and stability by preventing dead neurons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf767de",
   "metadata": {},
   "source": [
    "----\n",
    "## Training a CNN\n",
    "Staff:\n",
    "- Please discuss the selection process for optimizer and loss inputs\n",
    "- Define what learning rate is\n",
    "- Give an overview of 2-3 common loss functions and their behavior\n",
    "\n",
    "### Expanded Lecture Notes\n",
    "\n",
    "**Loss function:** Measures how wrong our predictions are.\n",
    "- For multi-class classification like CIFAR-10 → `CrossEntropyLoss`.\n",
    "- Binary labels → `BCEWithLogitsLoss`.\n",
    "- Regression → `MSELoss`.\n",
    "\n",
    "**Optimizer:** The algorithm that updates model parameters.\n",
    "- `SGD`: simple, but sensitive to learning rate.\n",
    "- `Adam`: adaptive, stable — great default.\n",
    "- `RMSProp`: similar to Adam but older.\n",
    "\n",
    "**Learning rate:** Controls the size of each update.\n",
    "- Too high → unstable / diverges.\n",
    "- Too low → slow / stuck.\n",
    "\n",
    "[This](https://www.geeksforgeeks.org/machine-learning/epoch-in-machine-learning/) reference will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910f2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Loss and optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9327ce76",
   "metadata": {},
   "source": [
    "### Q: What might happen if we changed our loss from __ to __ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217ce9c",
   "metadata": {},
   "source": [
    "### A:\n",
    "- Using **MSELoss** for classification usually causes slow learning and poor accuracy.\n",
    "- Using **BCEWithLogitsLoss** for multi-class problems produces incorrect shapes and fails.\n",
    "- Using **CrossEntropyLoss** is appropriate for problems with >2 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38868e01",
   "metadata": {},
   "source": [
    "### Q: What happens if the `learning_rate` parameter is too high? Or too low?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c969a87",
   "metadata": {},
   "source": [
    "### A:\n",
    "- Too high → the loss will oscillate or explode; training will fail.\n",
    "- Too low → training will get stuck or take far too long.\n",
    "- Proper learning rate scheduling can dramatically improve training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0828170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# STAFF: Please add check for early stopping!!!\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i,(images, labels) in enumerate(tqdm(train_loader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {loss.item():.4f} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8303225d",
   "metadata": {},
   "source": [
    "### Q: What happens if you increase `epochs`? Will performance always improve as `epochs` increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faaaf70",
   "metadata": {},
   "source": [
    "### A:\n",
    "Performance improves early on, but after a certain number of epochs the model begins to **overfit**:\n",
    "- Training accuracy increases\n",
    "- Validation accuracy decreases\n",
    "\n",
    "The model memorizes noise rather than learning generalizable features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f05bd",
   "metadata": {},
   "source": [
    "----\n",
    "## Validating a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d4cdd",
   "metadata": {},
   "source": [
    "Staff: Please add comments/explanations as needed to this code!\n",
    "\n",
    "Validation is where we measure the model's generalization. Key concepts:\n",
    "- **model.eval()** disables dropout and batchnorm updates.\n",
    "- **torch.no_grad()** ensures we don't compute gradients.\n",
    "- We compute accuracy across the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eb98ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff15a83",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34171286",
   "metadata": {},
   "source": [
    "## Analyzing Performance\n",
    "- Staff: prompt some reflection about the plot below\n",
    "\n",
    "Encourage students to think about:\n",
    "- Does accuracy improve smoothly or noisily?\n",
    "- Does it plateau? When?\n",
    "- Signs of overfitting?\n",
    "- Are more layers or data augmentation needed?\n",
    "\n",
    "This is a great opportunity to discuss *hyperparameter tuning*, *model capacity*, and *training dynamics*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91954382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy vs. epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
    "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
