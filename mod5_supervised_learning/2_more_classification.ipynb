{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe2bbd1",
   "metadata": {},
   "source": [
    "# Supervised Learning: More Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca579a74",
   "metadata": {},
   "source": [
    "- Practice implementing classifier algorithms\n",
    "- Make or find 2 small datasets that are clean (or walk through/prompt how to clean the data)\n",
    "\n",
    "Please write each of the following problems:\n",
    "1. For the first dataset, setup an outline/skeleton code of how to assemble a basic LinearSVC\n",
    "2. For the second, have them compare the different boundaries found by using `LinearSVC`, `SVC(kernel='linear)`, `SVC(kernel='rbf')`, and `SVC(kernel='rbf')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a808192",
   "metadata": {},
   "source": [
    "## LinearSVC Problem\n",
    "- example/guidance up front\n",
    "- discuss the problem/dataset\n",
    "- justify the use of a LinearSVC\n",
    "- discuss results using a confusion matrix and classification report\n",
    "- need to define precision vs. recall"
   ]
  },
  {
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Comparing SVM Kernels\n",
    "## Understanding How Different Kernels Handle Classification Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "## What are SVM Kernels?\n",
    "\n",
    "Support Vector Machines (SVMs) are powerful classifiers that try to find the best boundary to separate different classes of data.\n",
    "\n",
    "**The Problem**: Sometimes data can't be separated by a straight line!\n",
    "\n",
    "**Real-World Example**: Imagine trying to classify whether a student will pass or fail based on:\n",
    "- Hours studied per week\n",
    "- Hours of sleep per night\n",
    "\n",
    "Students who study too little OR sleep too little might fail. This creates a non-linear pattern that a straight line can't capture!\n",
    "\n",
    "### Different Kernel Types:\n",
    "\n",
    "1. **Linear Kernel**: Draws a straight line (or plane) to separate classes\n",
    "   - Best for: Linearly separable data\n",
    "   - Example: Separating tall vs short people by height\n",
    "\n",
    "2. **Polynomial Kernel**: Draws curved boundaries using polynomial functions\n",
    "   - Best for: Data with curved patterns\n",
    "   - Example: U-shaped or parabolic decision boundaries\n",
    "\n",
    "3. **RBF (Radial Basis Function) Kernel**: Creates circular/elliptical boundaries\n",
    "   - Best for: Complex, non-linear patterns\n",
    "   - Example: Islands of one class surrounded by another\n",
    "   - Most commonly used kernel!\n",
    "\n",
    "4. **Sigmoid Kernel**: Creates S-shaped boundaries\n",
    "   - Best for: Neural network-like decision boundaries\n",
    "   - Example: Smooth transitions between classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset_intro",
   "metadata": {},
   "source": [
    "## Our Dataset: Video Game Player Performance\n",
    "\n",
    "We'll classify players as **\"Beginner\"** or **\"Advanced\"** based on:\n",
    "- **Reaction Time** (milliseconds): How fast they react\n",
    "- **Accuracy** (%): How accurate they are\n",
    "\n",
    "The pattern is non-linear: Good players have BOTH fast reactions AND high accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a non-linear dataset (make_moons creates crescent-shaped clusters)\n",
    "np.random.seed(42)\n",
    "X, y = datasets.make_moons(n_samples=300, noise=0.15, random_state=42)\n",
    "\n",
    "# Scale features to represent our game stats\n",
    "# X[:, 0] = Reaction Time (100-400 ms)\n",
    "# X[:, 1] = Accuracy (60-95%)\n",
    "X[:, 0] = X[:, 0] * 150 + 250  # Scale to 100-400 range\n",
    "X[:, 1] = X[:, 1] * 35 + 60    # Scale to 60-95 range\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features (important for SVMs!)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], \n",
    "           c='skyblue', s=100, edgecolors='black', linewidth=1.5, label='Beginner', alpha=0.7)\n",
    "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], \n",
    "           c='coral', s=100, edgecolors='black', linewidth=1.5, label='Advanced', alpha=0.7)\n",
    "plt.xlabel('Reaction Time (ms)', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('Video Game Player Performance\\n(Can you draw a straight line to separate them?)', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(\"\\nüí° Notice: The classes form a crescent/moon shape - a straight line won't work!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reference_material",
   "metadata": {},
   "source": [
    "## Reference: Setting Up Different SVM Kernels\n",
    "\n",
    "In scikit-learn, we use the `SVC` (Support Vector Classifier) class:\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Linear Kernel\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "# Polynomial Kernel (degree controls the polynomial order)\n",
    "model = SVC(kernel='poly', degree=3)\n",
    "\n",
    "# RBF Kernel (gamma controls the influence of individual training points)\n",
    "model = SVC(kernel='rbf', gamma='scale')\n",
    "\n",
    "# Sigmoid Kernel\n",
    "model = SVC(kernel='sigmoid')\n",
    "\n",
    "# Then fit and predict as usual\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "```\n",
    "\n",
    "### Important Parameters:\n",
    "- **C**: Regularization parameter (higher = fit training data more closely)\n",
    "- **gamma**: Kernel coefficient for RBF, poly, sigmoid (higher = more complex boundaries)\n",
    "- **degree**: Polynomial degree for poly kernel (2, 3, 4, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1",
   "metadata": {},
   "source": [
    "### Q1: Train a Linear Kernel SVM\n",
    "Create and train an SVM with a linear kernel. Calculate its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear SVM\n",
    "svm_linear = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_linear = svm_linear.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "print(f\"Linear Kernel Accuracy: {accuracy_linear*100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_linear = confusion_matrix(y_test, y_pred_linear)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2",
   "metadata": {},
   "source": [
    "### Q2: Train a Polynomial Kernel SVM\n",
    "Create and train an SVM with a polynomial kernel (use degree=3). Calculate its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Polynomial SVM\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=1.0, random_state=42)\n",
    "svm_poly.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_poly = svm_poly.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)\n",
    "print(f\"Polynomial Kernel Accuracy: {accuracy_poly*100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_poly = confusion_matrix(y_test, y_pred_poly)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3",
   "metadata": {},
   "source": [
    "### Q3: Train an RBF Kernel SVM\n",
    "Create and train an SVM with an RBF (Radial Basis Function) kernel. Calculate its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RBF SVM\n",
    "svm_rbf = SVC(kernel='rbf', gamma='scale', C=1.0, random_state=42)\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "print(f\"RBF Kernel Accuracy: {accuracy_rbf*100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_rbf = confusion_matrix(y_test, y_pred_rbf)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q4",
   "metadata": {},
   "source": [
    "### Q4: Train a Sigmoid Kernel SVM\n",
    "Create and train an SVM with a sigmoid kernel. Calculate its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Sigmoid SVM\n",
    "svm_sigmoid = SVC(kernel='sigmoid', gamma='scale', C=1.0, random_state=42)\n",
    "svm_sigmoid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sigmoid = svm_sigmoid.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_sigmoid = accuracy_score(y_test, y_pred_sigmoid)\n",
    "print(f\"Sigmoid Kernel Accuracy: {accuracy_sigmoid*100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_sigmoid = confusion_matrix(y_test, y_pred_sigmoid)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization_intro",
   "metadata": {},
   "source": [
    "## Visualizing Decision Boundaries\n",
    "\n",
    "Now let's visualize how each kernel draws its decision boundary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_boundaries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with 4 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# List of models, titles, and accuracies\n",
    "models = [svm_linear, svm_poly, svm_rbf, svm_sigmoid]\n",
    "titles = ['Linear Kernel', 'Polynomial Kernel (degree=3)', 'RBF Kernel', 'Sigmoid Kernel']\n",
    "accuracies = [accuracy_linear, accuracy_poly, accuracy_rbf, accuracy_sigmoid]\n",
    "\n",
    "# Plot each model's decision boundary\n",
    "for idx, (model, title, accuracy) in enumerate(zip(models, titles, accuracies)):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        model,\n",
    "        X_train_scaled,\n",
    "        cmap='RdYlBu',\n",
    "        alpha=0.4,\n",
    "        ax=ax,\n",
    "        response_method='predict',\n",
    "        plot_method='pcolormesh',\n",
    "        shading='auto'\n",
    "    )\n",
    "    \n",
    "    # Plot training points\n",
    "    scatter1 = ax.scatter(X_train_scaled[y_train == 0, 0], X_train_scaled[y_train == 0, 1],\n",
    "                         c='blue', s=60, edgecolors='black', linewidth=1, \n",
    "                         label='Beginner', alpha=0.8)\n",
    "    scatter2 = ax.scatter(X_train_scaled[y_train == 1, 0], X_train_scaled[y_train == 1, 1],\n",
    "                         c='red', s=60, edgecolors='black', linewidth=1, \n",
    "                         label='Advanced', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Reaction Time (scaled)', fontsize=11)\n",
    "    ax.set_ylabel('Accuracy (scaled)', fontsize=11)\n",
    "    ax.set_title(f'{title}\\nAccuracy: {accuracy*100:.2f}%', \n",
    "                fontsize=12, fontweight='bold', pad=10)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Decision Boundary Colors:\")\n",
    "print(\"  Blue regions = Predicted as Beginner\")\n",
    "print(\"  Red regions = Predicted as Advanced\")\n",
    "print(\"  The line/curve between them is the decision boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confusion_matrices",
   "metadata": {},
   "source": [
    "## Comparing Model Performance\n",
    "\n",
    "Let's visualize all confusion matrices side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all confusion matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "confusion_matrices = [cm_linear, cm_poly, cm_rbf, cm_sigmoid]\n",
    "kernel_names = ['Linear', 'Polynomial', 'RBF', 'Sigmoid']\n",
    "\n",
    "for idx, (cm, name, accuracy) in enumerate(zip(confusion_matrices, kernel_names, accuracies)):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax,\n",
    "               annot_kws={'fontsize': 16, 'fontweight': 'bold'})\n",
    "    \n",
    "    ax.set_xlabel('Predicted Label', fontsize=11)\n",
    "    ax.set_ylabel('True Label', fontsize=11)\n",
    "    ax.set_title(f'{name} Kernel\\nAccuracy: {accuracy*100:.2f}%', \n",
    "                fontsize=12, fontweight='bold', pad=10)\n",
    "    ax.set_xticklabels(['Beginner', 'Advanced'])\n",
    "    ax.set_yticklabels(['Beginner', 'Advanced'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Confusion Matrix Guide:\")\n",
    "print(\"  Top-Left: True Beginners correctly classified as Beginners\")\n",
    "print(\"  Top-Right: True Beginners incorrectly classified as Advanced\")\n",
    "print(\"  Bottom-Left: True Advanced incorrectly classified as Beginners\")\n",
    "print(\"  Bottom-Right: True Advanced correctly classified as Advanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_table",
   "metadata": {},
   "source": [
    "## Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Kernel': ['Linear', 'Polynomial', 'RBF', 'Sigmoid'],\n",
    "    'Accuracy': [f\"{acc*100:.2f}%\" for acc in accuracies],\n",
    "    'Correct Predictions': [cm.trace() for cm in confusion_matrices],\n",
    "    'Incorrect Predictions': [cm.sum() - cm.trace() for cm in confusion_matrices]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KERNEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find best performing kernel\n",
    "best_idx = np.argmax(accuracies)\n",
    "print(f\"\\nüèÜ Best Performing Kernel: {kernel_names[best_idx]}\")\n",
    "print(f\"   Accuracy: {accuracies[best_idx]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_question",
   "metadata": {},
   "source": [
    "### Q5: Analyze the Results\n",
    "\n",
    "Look at the decision boundary plots and confusion matrices above. Answer the following:\n",
    "\n",
    "a. **Decision Boundaries**: Describe the shape of each kernel's decision boundary. Which one looks like it fits the crescent shape of the data best?\n",
    "\n",
    "b. **Linear Kernel Performance**: Why does the linear kernel struggle with this dataset? What pattern in the data makes a straight line insufficient?\n",
    "\n",
    "c. **Best Kernel**: Which kernel achieved the highest accuracy? Based on the decision boundary plot, explain WHY this kernel performed best.\n",
    "\n",
    "d. **Confusion Matrix Insights**: Compare the confusion matrices. Do certain kernels make more mistakes on Beginners vs Advanced players? What does this tell you?\n",
    "\n",
    "e. **Real-World Application**: If you were building a video game matchmaking system, which kernel would you choose and why? Consider both accuracy AND the shape of the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_answer",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Different Kernels for Different Problems:\n",
    "- **Linear**: Fast and simple, but only works for linearly separable data\n",
    "- **Polynomial**: Good for curved boundaries, but can be sensitive to degree parameter\n",
    "- **RBF**: Most versatile, handles complex non-linear patterns well (often the default choice!)\n",
    "- **Sigmoid**: Similar to neural network activation, good for smooth boundaries\n",
    "\n",
    "### Choosing the Right Kernel:\n",
    "1. **Try Linear first**: Always start simple! If your data is linearly separable, linear is fastest\n",
    "2. **Use RBF for complex patterns**: When data has circular/complex clusters, RBF usually wins\n",
    "3. **Consider Polynomial for specific curves**: When you know the pattern is polynomial\n",
    "4. **Visualize when possible**: Decision boundaries help you understand what the model learned\n",
    "\n",
    "### Important Reminders:\n",
    "‚úÖ **Always scale your data** before using SVMs (they're sensitive to feature scales)\n",
    "\n",
    "‚úÖ **No single kernel is always best** - it depends on your data!\n",
    "\n",
    "‚úÖ **More complex ‚â† better** - Sometimes simple linear boundaries work great\n",
    "\n",
    "‚úÖ **Visualize your results** - Decision boundaries reveal if your kernel makes sense\n",
    "\n",
    "### Real-World Applications:\n",
    "- **Image Classification**: RBF kernels for recognizing handwritten digits\n",
    "- **Text Classification**: Linear kernels for spam detection\n",
    "- **Medical Diagnosis**: RBF kernels for disease prediction\n",
    "- **Finance**: Polynomial kernels for stock trend prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
